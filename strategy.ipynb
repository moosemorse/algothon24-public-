{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "024e9539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'release_5915.crypt' already exists, skipping download.\n",
      "File 'release_6043.crypt' already exists, skipping download.\n",
      "File 'release_5979.crypt' already exists, skipping download.\n",
      "File 'release_5723.crypt' already exists, skipping download.\n",
      "File 'release_5787.crypt' already exists, skipping download.\n",
      "File 'release_5595.crypt' already exists, skipping download.\n",
      "File 'release_5531.crypt' already exists, skipping download.\n",
      "File 'release_5659.crypt' already exists, skipping download.\n",
      "File 'release_5851.crypt' already exists, skipping download.\n",
      "File 'release_8475.crypt' already exists, skipping download.\n",
      "File 'release_8411.crypt' already exists, skipping download.\n",
      "File 'release_8347.crypt' already exists, skipping download.\n",
      "File 'release_8283.crypt' already exists, skipping download.\n",
      "File 'release_8219.crypt' already exists, skipping download.\n",
      "File 'release_8155.crypt' already exists, skipping download.\n",
      "File 'release_8091.crypt' already exists, skipping download.\n",
      "File 'release_8027.crypt' already exists, skipping download.\n",
      "File 'release_7963.crypt' already exists, skipping download.\n",
      "File 'release_7899.crypt' already exists, skipping download.\n",
      "File 'release_7835.crypt' already exists, skipping download.\n",
      "File 'release_7771.crypt' already exists, skipping download.\n",
      "File 'release_7643.crypt' already exists, skipping download.\n",
      "File 'release_7707.crypt' already exists, skipping download.\n",
      "File 'release_7579.crypt' already exists, skipping download.\n",
      "File 'release_7451.crypt' already exists, skipping download.\n",
      "File 'release_7515.crypt' already exists, skipping download.\n",
      "File 'release_7387.crypt' already exists, skipping download.\n",
      "File 'release_7323.crypt' already exists, skipping download.\n",
      "File 'release_7259.crypt' already exists, skipping download.\n",
      "File 'release_7131.crypt' already exists, skipping download.\n",
      "File 'release_7195.crypt' already exists, skipping download.\n",
      "File 'release_7003.crypt' already exists, skipping download.\n",
      "File 'release_7067.crypt' already exists, skipping download.\n",
      "File 'release_6939.crypt' already exists, skipping download.\n",
      "File 'release_6811.crypt' already exists, skipping download.\n",
      "File 'release_6875.crypt' already exists, skipping download.\n",
      "File 'release_6683.crypt' already exists, skipping download.\n",
      "File 'release_6747.crypt' already exists, skipping download.\n",
      "File 'release_6619.crypt' already exists, skipping download.\n",
      "File 'release_6555.crypt' already exists, skipping download.\n",
      "File 'release_6491.crypt' already exists, skipping download.\n",
      "File 'release_6427.crypt' already exists, skipping download.\n",
      "File 'release_6363.crypt' already exists, skipping download.\n",
      "File 'release_6299.crypt' already exists, skipping download.\n",
      "File 'release_6171.crypt' already exists, skipping download.\n",
      "File 'release_6235.crypt' already exists, skipping download.\n",
      "File 'release_6107.crypt' already exists, skipping download.\n",
      "File 'release_5339.crypt' already exists, skipping download.\n",
      "File 'release_5467.crypt' already exists, skipping download.\n",
      "File 'release_5403.crypt' already exists, skipping download.\n",
      "File 'release_5211.crypt' already exists, skipping download.\n",
      "File 'release_5275.crypt' already exists, skipping download.\n",
      "File 'release_5083.crypt' already exists, skipping download.\n",
      "File 'release_5147.crypt' already exists, skipping download.\n",
      "File 'release_5019.crypt' already exists, skipping download.\n",
      "File 'release_4891.crypt' already exists, skipping download.\n",
      "File 'release_4955.crypt' already exists, skipping download.\n",
      "File 'release_4699.crypt' already exists, skipping download.\n",
      "File 'release_4763.crypt' already exists, skipping download.\n",
      "File 'release_4827.crypt' already exists, skipping download.\n",
      "File 'release_4571.crypt' already exists, skipping download.\n",
      "File 'release_4507.crypt' already exists, skipping download.\n",
      "File 'release_4635.crypt' already exists, skipping download.\n",
      "File 'release_4443.crypt' already exists, skipping download.\n",
      "File 'release_4315.crypt' already exists, skipping download.\n",
      "File 'release_4379.crypt' already exists, skipping download.\n",
      "File 'release_4251.crypt' already exists, skipping download.\n",
      "File 'release_4123.crypt' already exists, skipping download.\n",
      "File 'release_4187.crypt' already exists, skipping download.\n",
      "File 'release_4059.crypt' already exists, skipping download.\n",
      "File 'release_3995.crypt' already exists, skipping download.\n",
      "File 'release_3931.crypt' already exists, skipping download.\n",
      "File 'release_3867.crypt' already exists, skipping download.\n",
      "File 'release_3739.crypt' already exists, skipping download.\n",
      "File 'release_3803.crypt' already exists, skipping download.\n",
      "File 'release_3675.crypt' already exists, skipping download.\n",
      "File 'release_3611.crypt' already exists, skipping download.\n",
      "File 'release_3547.crypt' already exists, skipping download.\n"
     ]
    }
   ],
   "source": [
    "import cryptinstall\n",
    "cryptinstall.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39f91db-2d5c-47c6-a310-880ad571a852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'strat_4': 0.1,\n",
       " 'strat_3': 0.1,\n",
       " 'strat_5': 0.1,\n",
       " 'strat_7': 0.1,\n",
       " 'strat_8': 0.1,\n",
       " 'strat_21': 0.1,\n",
       " 'strat_25': 0.1,\n",
       " 'strat_24': 0.1,\n",
       " 'strat_19': 0.1,\n",
       " 'strat_26': 0.1,\n",
       " 'team_name': 'algothoners123',\n",
       " 'passcode': 'RagingMartians'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def get_positions(pos_dict):\n",
    "    pos = pd.Series(pos_dict)\n",
    "    pos = pos.replace([np.inf, -np.inf], np.nan)\n",
    "    pos = pos.dropna()\n",
    "    pos = pos / pos.abs().sum()\n",
    "    pos = pos.clip(-0.1, 0.1)\n",
    "    if pos.abs().max() / pos.abs().sum() > 0.1:\n",
    "        raise ValueError(f\"Portfolio too concentrated {pos.abs().max()=} / {pos.abs().sum()=}\")\n",
    "    return pos\n",
    "\n",
    "\n",
    "def get_submission_dict(\n",
    "        pos_dict,\n",
    "        your_team_name: str = \"algothoners123\",\n",
    "        your_team_passcode: str = \"RagingMartians\",\n",
    "):\n",
    "    return {\n",
    "        **get_positions(pos_dict).to_dict(),\n",
    "        **{\n",
    "            \"team_name\": your_team_name,\n",
    "            \"passcode\": your_team_passcode,\n",
    "        },\n",
    "    }\n",
    "\n",
    "#     get_submission_dict(\n",
    "#         {**{f\"strat_{i}\": 0.1 for i in range(10)}, \"strat_bad\": np.nan, \"strat_bad2\": -np.inf}\n",
    "#     )\n",
    "#\n",
    "{'strat_4': 0.1,\n",
    " 'strat_3': 0.1,\n",
    " 'strat_5': 0.1,\n",
    " 'strat_7': 0.1,\n",
    " 'strat_8': 0.1,\n",
    " 'strat_21': 0.1,\n",
    " 'strat_25': 0.1,\n",
    " 'strat_24': 0.1,\n",
    " 'strat_19': 0.1,\n",
    " 'strat_26': 0.1,\n",
    " 'team_name': 'algothoners123',\n",
    " 'passcode': 'RagingMartians'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "107db8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID for joearrowsmith0@gmail.com: U080GCRATP1\n",
      "['oUFtGMsMEEyPCCP6', 'GMJVDf4WWzsV1hfL', 'PSI9bPh4aM3iQMuE', '1vA9LaAZDTEKPePs', '0n74wuaJ2wm8A4qC', 'mXTi0PZ5oL731Zqx', 'hjhMuDFZTCJEcI6q', 'uZwgENGlQ4m4nSz6', 'HkpYXpKituGernrk', 'WM5xrwsJiBCo4Unp', 'InhVD4qy1Vmbpl5c', 'VRiYLce0BKVSdrft', 'UR7git7mIlV7HdyY', 'scZ5oIa3vp1uzE4S', 'ZJ1eGJfUWUuK5rq6', 'Zp4NnKkrC6OT0xms', 'WPcFk8FofuBmfUzO', 'hpuTAsG3v5av6J0D', 'iqKVo38SFhsSz9qX', 'YaYVHkUbVZkzNItu', 'KZpaNLmv4lDHBN6O', '9YAePHMaPzZKmsmv', 'sL7KZHNduMf2Cy5D', 'dcEQvAF3Ch7r6RDn', 'PEypfZiNg7NA519d', 'MwCvLvuQlJsZMr1I', 'LR2tgboMGxWtKhjM', 'ljo2F8g5X6TWJXmX', 'oGIYkvt7AwKyb22t', 'F8CvtiKofpaT7IeO', 'CfEJCI8NjykYKV73', '9xzhWOAuImRy1cQB', 'bsCATJi4sHpcSZFZ', 'GnkFGu3eeJPoHs4A', 'l9Du3GZLJkFwiFug', 'udaxEolZcR3jRgDO', 'fgPBeYhqf8n52qKF', 'ZAH2rZHDFABdhC5k', 'WlWszEj1WRNCfRzF', 'F7SmHeLnWpqStZIa', '7uo98YuRny2pxsOd', 'uahRUnmsahYFKjFd', 'Obajj20gRXYbOn87', 'h0u3vp0gjJ6Jro9S', 'SS1ImJUJBkYGpzj0', 'knPxrnUGohNFbMW0', 'cbdRcR1ffKLFHImQ', 'vc92yysX7aX7cmSz', 'mnwLBjfPuF9oNkrG', 'lZKjul2Y81gbAGy7', 'Zj0pkgGiHoi5OIu2', 'IVJZjpv6CF6i04rF', 'Ctq4Ii5KIPwONWlJ', 'wq7TOuHJ6U2DDiri', 'XLJlbea9RffVT8fC', 'ytOZ8hfbaglDNeCg', 'hgXhak0keKoHq6vo', 'uphRSKg2hUzCSXJu', 'KchBrDmLLUZ4u0GK', 'd0vPZFUs9AmW74TW', 'aGwArWBFD6rKAZhR', 'v3SDNYVc8gYdAJ7c', 'gaJ8TDE6m5QDBXtM', 'OcxwRUinsNa30IUH', '7vCjQ4BN2RYzSecL', 'cyDyXDTHArIZsS9r', 'yXGDMFcczw2wX6Gg', 'tVPs6561FIqzBI56', 'nnvwM9JKoaWYKsmO', '5WmUmommCTMalwFy', 'xwDXIhUaJe9V4bVR', 'cSh9mVS1ejq39Tu8', 'j2RsSSBEEYS2BLE4', 'iZUYFYzWmiFETC1H', 'bQ0iwgq47y03k5sl', 'e2tTR7g9oM2ttIzH', 'txpr5wCyFGPpKoqK', 'IToOiV72S4vRSmcn', 'CONGRATSYOUAREDONE']\n",
      "User ID for joearrowsmith0@gmail.com: U080GCRATP1\n",
      "[]\n",
      "User ID for joearrowsmith0@gmail.com: U080GCRATP1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_data\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Load and clean data\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m combined_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_clean_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m combined_data\u001b[38;5;241m.\u001b[39mreplace([np\u001b[38;5;241m.\u001b[39minf, \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf], np\u001b[38;5;241m.\u001b[39mnan, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Replace infinite values\u001b[39;00m\n\u001b[0;32m     24\u001b[0m combined_data\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Fill NaNs with zeros\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m, in \u001b[0;36mload_and_clean_data\u001b[1;34m(files)\u001b[0m\n\u001b[0;32m     16\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mto_numeric, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Convert columns to numeric\u001b[39;00m\n\u001b[0;32m     17\u001b[0m         all_data\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m---> 18\u001b[0m combined_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m combined_data\n",
      "File \u001b[1;32mc:\\Users\\HP Envy 13\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\HP Envy 13\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32mc:\\Users\\HP Envy 13\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import cryptpandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from dictionary_generation import get_dict\n",
    "\n",
    "# List of encrypted files and passwords\n",
    "files = get_dict()\n",
    "\n",
    "# Function to load and clean data\n",
    "def load_and_clean_data(files):\n",
    "    all_data = []\n",
    "    for i, file in enumerate(files):\n",
    "        if i == len(files) - 1: \n",
    "            data = cryptpandas.read_encrypted(path=file[\"path\"], password=file[\"password\"])\n",
    "            data = data.apply(pd.to_numeric, errors='coerce')  # Convert columns to numeric\n",
    "            all_data.append(data)\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "    return combined_data\n",
    "\n",
    "# Load and clean data\n",
    "combined_data = load_and_clean_data(files)\n",
    "combined_data.replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace infinite values\n",
    "combined_data.fillna(0, inplace=True)  # Fill NaNs with zeros\n",
    "combined_data = combined_data.apply(pd.to_numeric, errors='coerce')  # Ensure numeric data\n",
    "\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4383b53fedd720e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T23:09:34.425691Z",
     "start_time": "2024-11-16T23:09:30.743934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Portfolio Weights with Black-Litterman Model:\n",
      "    Strategy  Posterior Expected Return    Weight\n",
      "0    strat_0               5.000000e-02  0.010417\n",
      "1    strat_1               3.771318e+07  0.010417\n",
      "2    strat_2               3.771318e+07  0.010417\n",
      "3    strat_3               9.356753e+08  0.010417\n",
      "4    strat_4              -9.100891e+07  0.010417\n",
      "..       ...                        ...       ...\n",
      "91  strat_91              -7.377071e+08  0.010417\n",
      "92  strat_92               3.002814e+08  0.010417\n",
      "93  strat_93              -6.333471e+09  0.010417\n",
      "94  strat_94               4.400394e+08  0.010417\n",
      "95  strat_95              -7.952491e+08  0.010417\n",
      "\n",
      "[96 rows x 3 columns]\n",
      "Total Weight: 1.0\n",
      "Portfolio with formatted spacing saved to optimized_portfolio_formatted.txt\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with zero standard deviation\n",
    "volatility = combined_data.std()\n",
    "zero_volatility = volatility[volatility == 0].index\n",
    "combined_data.drop(columns=zero_volatility, inplace=True)\n",
    "\n",
    "# Recalculate mean returns and covariance matrix\n",
    "mean_returns = combined_data.mean()\n",
    "volatility = combined_data.std()\n",
    "Sigma = combined_data.cov()\n",
    "\n",
    "# Calculate equilibrium returns (Pi)\n",
    "num_strategies = len(mean_returns)\n",
    "w_mkt = np.array([1 / num_strategies] * num_strategies)  # Equal market weights\n",
    "delta = 2.5  # Risk aversion coefficient\n",
    "Pi = delta * Sigma.dot(w_mkt)\n",
    "\n",
    "# Define Views\n",
    "P = np.zeros((2, num_strategies))  # Views matrix\n",
    "Q = np.zeros(2)  # Expected returns vector\n",
    "\n",
    "# Map strategies to indices\n",
    "strategies = mean_returns.index.tolist()\n",
    "strategy_indices = {strategy: idx for idx, strategy in enumerate(strategies)}\n",
    "\n",
    "# View 1: Strategy 1 expected to return 5%\n",
    "P[0, strategy_indices[strategies[0]]] = 1\n",
    "Q[0] = 0.05\n",
    "\n",
    "# View 2: Strategy 2 expected to outperform Strategy 3 by 1%\n",
    "P[1, strategy_indices[strategies[1]]] = 1\n",
    "P[1, strategy_indices[strategies[2]]] = -1\n",
    "Q[1] = 0.01\n",
    "\n",
    "# Black-Litterman parameters\n",
    "tau = 0.05  # Scaling factor\n",
    "Omega = np.diag(np.diag(tau * P.dot(Sigma).dot(P.T)))  # Uncertainty matrix\n",
    "\n",
    "# Compute posterior returns\n",
    "inv_tau_Sigma = np.linalg.pinv(tau * Sigma)  # Use pseudo-inverse for stability\n",
    "M = inv_tau_Sigma + P.T.dot(np.linalg.inv(Omega)).dot(P)\n",
    "RHS = inv_tau_Sigma.dot(Pi) + P.T.dot(np.linalg.inv(Omega)).dot(Q)\n",
    "E_r = np.linalg.pinv(M).dot(RHS)  # Use pseudo-inverse for posterior returns\n",
    "\n",
    "# Constraints and bounds\n",
    "bounds = [(0, 0.1) for _ in range(num_strategies)]  # Max weight = 10%\n",
    "constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1})  # Weights sum to 1\n",
    "\n",
    "# Optimization function\n",
    "def objective_function(weights, expected_returns, cov_matrix, risk_aversion):\n",
    "    portfolio_return = np.dot(weights, expected_returns)\n",
    "    portfolio_variance = weights.T.dot(cov_matrix).dot(weights)\n",
    "    return - (portfolio_return - risk_aversion * portfolio_variance)  # Maximize risk-adjusted return\n",
    "\n",
    "# Initial guess: Equal weights\n",
    "initial_guess = np.array([1 / num_strategies] * num_strategies)\n",
    "\n",
    "# Optimize weights\n",
    "risk_aversion = 0.5  # Adjust for return-risk tradeoff\n",
    "result = minimize(\n",
    "    objective_function,\n",
    "    initial_guess,\n",
    "    args=(E_r, Sigma, risk_aversion),\n",
    "    method='SLSQP',\n",
    "    bounds=bounds,\n",
    "    constraints=constraints\n",
    ")\n",
    "\n",
    "# Extract weights\n",
    "optimized_weights = result.x\n",
    "optimized_weights[optimized_weights < 1e-5] = 0  # Set negligible weights to 0\n",
    "\n",
    "# Normalize weights to ensure they sum to 1 while respecting bounds\n",
    "if np.sum(optimized_weights) > 1:\n",
    "    scaling_factor = 1 / np.sum(optimized_weights)\n",
    "    optimized_weights = np.minimum(optimized_weights * scaling_factor, 0.1)\n",
    "\n",
    "# Re-normalize weights to sum to exactly 1\n",
    "optimized_weights /= np.sum(optimized_weights)\n",
    "\n",
    "# Create portfolio weights DataFrame\n",
    "portfolio_weights = pd.DataFrame({\n",
    "    'Strategy': strategies,\n",
    "    'Posterior Expected Return': E_r,\n",
    "    'Weight': optimized_weights\n",
    "}).sort_values(by='Weight', ascending=False)\n",
    "\n",
    "# Display results\n",
    "print(\"Optimized Portfolio Weights with Black-Litterman Model:\")\n",
    "print(portfolio_weights)\n",
    "print(\"Total Weight:\", np.sum(optimized_weights))\n",
    "\n",
    "# Extract the required columns and create a dictionary\n",
    "portfolio_dict = portfolio_weights.set_index('Strategy')['Weight'].to_dict()\n",
    "\n",
    "# Save the dictionary to a text file with an empty line between each entry\n",
    "output_file = 'optimized_portfolio_formatted.txt'\n",
    "portfolio_dict = get_submission_dict(portfolio_dict)\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"{\\n\")\n",
    "    for key, value in portfolio_dict.items():\n",
    "        if key == 'team_name' or key == 'passcode': \n",
    "            f.write(f\" '{key}': '{value}',\\n\")\n",
    "        else: \n",
    "            f.write(f\" '{key}': {value},\\n\")\n",
    "    f.write(\"}\")\n",
    "\n",
    "print(f\"Portfolio with formatted spacing saved to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a8ff61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
